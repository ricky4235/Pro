{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 看一下連續變量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "continual_var = listing.select_dtypes(np.number).columns\n",
    "no_null_col = drop_outlier_price_condition[continual_var].isnull().sum()==0\n",
    "no_null_col = no_null_col[no_null_col == True].index.tolist()\n",
    "\n",
    "#移除掉id類別的變量\n",
    "no_null_col = no_null_col[3:]\n",
    "\n",
    "corr = drop_outlier_price_condition[no_null_col].dropna().corr()\n",
    "plt.figure(figsize = (12,12))\n",
    "sns.set(font_scale = 1)\n",
    "sns.heatmap(corr , cbar=True , annot = True  , fmt = '.2f')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "看到price那行，我們可以發現guests included 以及accommodates跟price蠻有關係的。\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 嘗試建立定價模型\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "接下來我們把自己當作Airbnb的資料科學家，嘗試一下定價模型的建立。\n",
    "那第一步還是清資料，將離群值、NaN值太多的變數刪掉。\n",
    "另外重複值太多的變數也要刪掉，因為如果表現不出差異性，其實對模型的學習是沒什麼幫助的。\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#把離群值拿掉來建模\n",
    "listing = drop_outlier_price_condition\n",
    "\n",
    "#刪除NaN值\n",
    "no_null_col = listing.isnull().sum()==0\n",
    "no_null_col = no_null_col[no_null_col == True].index.tolist()\n",
    "#放回去listing\n",
    "listing = listing[no_null_col]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "我們還要對文字變量分詞與編碼，這部分利用詞頻統計就好囉！\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "listing.amenities = listing.amenities.str.replace('[{}]','').str.replace('\"' , '')\n",
    "#用 \" , \" 分隔就可以很輕鬆分好詞囉！\n",
    "count_vectorizer = CountVectorizer(tokenizer=lambda x:x.split(','))\n",
    "amenities = count_vectorizer.fit_transform(listing.amenities)\n",
    "df_amenities = pd.DataFrame(amenities.toarray() , \n",
    "                            columns=count_vectorizer.get_feature_names())\n",
    "df_amenities = df_amenities.drop('' , 1)\n",
    "\n",
    "df_amenities.head()\n",
    "\n",
    "# Encoding and process category variable\n",
    "\n",
    "continual_var = listing.select_dtypes(np.number).columns.drop(['id','scrape_id', 'host_id'])\\\n",
    ".tolist()\n",
    "\n",
    "cat_var = []\n",
    "for col in listing.columns :\n",
    "    if col not in continual_var:\n",
    "        cat_var.append(col)\n",
    "    \n",
    "#看一下哪些變量對建模是沒什麼幫助的\n",
    "cat_var\n",
    "\n",
    "#挑出這些跟連續變量中的id，基本上資料一致（比如國家都是臺灣）、差異太多的變數對建模都沒什麼幫助。\n",
    "useless_var = ['id','host_id',\n",
    " 'scrape_id' ,'listing_url' ,'picture_url','host_url','country_code', 'country',\n",
    "               'experiences_offered','street','smart_location'\n",
    "           \n",
    "              \n",
    "              \n",
    "              \n",
    "              ]\n",
    "final_cat_var = []\n",
    "for var in cat_var:\n",
    "    if var not in useless_var:\n",
    "        final_cat_var.append(var)\n",
    "final_cat_var\n",
    "\n",
    "\n",
    "df = listing[final_cat_var + continual_var]\n",
    "df[final_cat_var]\n",
    "\n",
    "# 先將True False 作轉換\n",
    "columns =  [ 'has_availability' ,'is_location_exact', 'requires_license', 'instant_bookable',\n",
    "                   'require_guest_profile_picture', 'require_guest_phone_verification',\n",
    "           'is_business_travel_ready',\n",
    "           ]\n",
    "for c in columns:\n",
    "    df[c] = df[c].replace('f',0,regex=True)\n",
    "    df[c] = df[c].replace('t',1,regex=True)\n",
    "\n",
    "df = pd.concat([df , df_amenities] , axis = 1 , join = 'inner')\n",
    "df.head()\n",
    "\n",
    "# 更細緻地處理類別變量\n",
    "\n",
    "\"\"\"\n",
    "TODO:\n",
    "* host verifications : 刪去\n",
    "* neighbourhood_cleansed  : mean encoding\n",
    "* property_type : mean encoding ，有明顯差異\n",
    "* amenities ：刪掉，已經轉one hot了\n",
    "* room_type\t:label encoding (似乎存在order relationship)\n",
    "* bed_type\t: label encoding （似乎存在order relationship）\n",
    "* extra people : 轉換為連續變量\n",
    "* calendar_update ：轉換為連續變量\n",
    "* calendar_last_scraped : 刪掉\n",
    "* cancellation_policy : mean encoding\n",
    "\n",
    "接下來處理extra people 、calendar_update ：轉換為連續變量。\n",
    "不過calendar update有點棘手，我們想把資料轉換為以天為單位的連續資料。\n",
    "\n",
    "仔細看，我們發現extra people有少許缺失值，所以我們簡單用mode填補\n",
    "\n",
    "這邊我們使用L1、L2 Regression來做baseline，其中alphas是一個生成0.01~0.001（10的-2~-3次方）的矩陣，\n",
    "\n",
    "將之傳入model中，回傳的是alphas中各個數分別當作正則係數時的L2 CV model 。\n",
    "\n",
    "\n",
    "\n",
    "R square只有51%，fit 的很不好\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 清理缺失值\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 建模\n",
    "\n",
    "\n",
    "\n",
    "# Baseline model\n",
    "\n",
    "# 隨機森林\n",
    "\n",
    "#建立函數\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def one_hot_encoder(feature ,df):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    this_feature = count_vectorizer.fit_transform(df[feature])\n",
    "    temp_df = pd.DataFrame(this_feature.toarray() , \n",
    "                                columns=count_vectorizer.get_feature_names())\n",
    " \n",
    "    return temp_df\n",
    "\n",
    "\n",
    "\n",
    "def mean_encoder(df , obj_columns , obj_Y):\n",
    "    for col in obj_columns:\n",
    "        temp_df = df.groupby([col])[obj_Y].mean().reset_index()\n",
    "        #將col . col_mean作為新的column\n",
    "        temp_df.columns = [col , f\"{col}_mean\"]\n",
    "        df = pd.merge(df , temp_df , on = col , how ='left')\n",
    "        df = df.drop([col] , axis = 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#Label encoder\n",
    "df['room_type'] = LabelEncoder().fit_transform(df['room_type'])\n",
    "df['bed_type'] = LabelEncoder().fit_transform(df['bed_type'])\n",
    "\n",
    "# drop\n",
    "drop_ls = ['host_verifications','amenities','calendar_last_scraped'] \n",
    "df = df.drop(drop_ls , axis = 1)\n",
    "\n",
    "#mean encoder\n",
    "mean_ls = ['neighbourhood_cleansed' ,'property_type','cancellation_policy']\n",
    "df = mean_encoder(df , mean_ls , 'price')\n",
    "\n",
    "#發現還有漏網之魚，這些資料都沒有差異性\n",
    "df = df.drop(['last_scraped','is_business_travel_ready' ,'has_availability','requires_license'] , axis = 1)\n",
    "\n",
    "\n",
    "temp_df = pd.DataFrame()\n",
    "temp_df['raw'] = df['calendar_updated']\n",
    "#先將today設為0\n",
    "temp_df['raw'] = temp_df.raw.replace('today','0').str.replace('never','-1').str.replace('yesterday' , '1')\n",
    "temp_df['raw'] = temp_df.raw.replace('a week ago' , '1 weeks ago')\n",
    "#將day抽出\n",
    "temp_df['days'] = temp_df['raw'].str.contains('day')\n",
    "temp_df['days']=  temp_df.days.astype(str).map({'True':1 , 'nan':0 , 'False':0})\n",
    "\n",
    "#將weeks抽出\n",
    "temp_df['weeks'] = temp_df['raw'].str.contains('week')\n",
    "temp_df['weeks']=  temp_df.weeks.astype(str).map({'True':7 , 'nan':0 , 'False':0})\n",
    "#將月抽出\n",
    "temp_df['months'] = temp_df['raw'].str.contains('months')\n",
    "temp_df['months']=  temp_df.months.astype(str).map({'True':30 , 'nan':0 , 'False':0})\n",
    "temp_df['raw'] = temp_df.raw.str[:2].astype(int)\n",
    "\n",
    "temp_df = temp_df.replace(0,1)\n",
    "df['calendar_updated'] = temp_df.raw*temp_df.days*temp_df.months*temp_df.weeks\n",
    "\n",
    "\n",
    "\n",
    "print('缺失值數目' , df.isnull().sum().sum())\n",
    "print('眾數' , df.extra_people.mode())\n",
    "df.fillna(value = 0 , inplace=True)\n",
    "print('缺失值數目' , df.isnull().sum().sum())\n",
    "#處理extra people\n",
    "df.extra_people = df.extra_people.str[:-3]\n",
    "df.extra_people = df.extra_people.str.replace('$','')\n",
    "df.extra_people = df.extra_people.str.replace(',','')\n",
    "df.extra_people = df.extra_people.str.replace('.','')\n",
    "df.extra_people = df.extra_people.astype(float)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#選出連續數值\n",
    "mean_ls = ['neighbourhood_cleansed_mean', 'property_type_mean', 'cancellation_policy_mean' , \n",
    "          'calendar_updated' , 'extra_people']\n",
    "continual_var = listing.select_dtypes(np.number).columns.drop(['id','scrape_id', 'host_id']).tolist()\n",
    "for mean_code in mean_ls:\n",
    "    continual_var.append(mean_code)\n",
    "\n",
    "continual_var.remove('price')\n",
    "    #將連續數值的變數做標準化\n",
    "continue_df = pd.DataFrame(scale(df[continual_var]))\n",
    "#取代掉原本的連續數值\n",
    "train_df = pd.concat([df , continue_df]  , axis = 1 , join='inner').drop( continual_var, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "#切分資料集\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "train_df = df.copy()\n",
    "\n",
    "#轉換價格分佈\n",
    "train_df.price = (np.log(train_df.price))\n",
    "\n",
    "\n",
    "#分離自變數、應變數\n",
    "y = train_df['price']\n",
    "x = train_df.drop('price' , axis = 1)\n",
    "\n",
    "#切分資料\n",
    "X_train , X_test , Y_train , Y_test = train_test_split(x ,y , test_size = 0.25 , random_state = 42)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "\n",
    "#Ridge Regression\n",
    "alphas = np.logspace(-2 , 3 , 100 , base = 10)\n",
    "model = RidgeCV(alphas= alphas , store_cv_values= True)\n",
    "model.fit(X_train , Y_train)\n",
    "\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "rmse_rf = (mean_squared_error(Y_test , y_test_pred))**(1/2)\n",
    "\n",
    "\n",
    "\n",
    "print('RMSE test :%.3f'%rmse_rf)\n",
    "print('R square test :%.3f '%(r2_score(Y_test , y_test_pred)))\n",
    "\n",
    "#Lasso regression\n",
    "\n",
    "lasso_alphas = np.logspace(-3 , 0 , 100 , base = 10)\n",
    "model = LassoCV(alphas= lasso_alphas  ,cv = 10 ) #Search the min MSE by cv\n",
    "model.fit(X_train , Y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "rmse_rf = (mean_squared_error(Y_test , y_test_pred))**(1/2)\n",
    "\n",
    "\n",
    "\n",
    "print('RMSE test :%.3f'%rmse_rf)\n",
    "print('R square test :%.3f '%(r2_score(Y_test , y_test_pred)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "#建立Random forest的regression model\n",
    "model = RandomForestRegressor(n_estimators= 200 , criterion='mse' ,max_depth=20,\n",
    "                              random_state= 42\n",
    "                             )\n",
    " \n",
    "          \n",
    "\n",
    "model.fit(X_train , Y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "rmse_rf = (mean_squared_error(Y_test , y_test_pred))**(1/2)\n",
    "\n",
    "print('RMSE test :%.3f'%rmse_rf)\n",
    "print('R square test :%.3f '%(r2_score(Y_test , y_test_pred)))\n",
    "\n",
    "coefs_df = pd.DataFrame()\n",
    "\n",
    "coefs_df['estimate_var'] = df.drop('price' , axis = 1).columns\n",
    "coefs_df['coefs'] = model.feature_importances_\n",
    "coefs_df = coefs_df.sort_values('coefs' , ascending = False).head(10)\n",
    "plt.figure(figsize =  (8,10))\n",
    "sns.barplot( coefs_df.coefs ,coefs_df.estimate_var , orient='h')\n",
    "plt.title('Feature importance')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "模型的解釋能力上升到了73.3%，感覺還不錯！\n",
    "\n",
    "\n",
    "\n",
    "我們也可以將變數重要性畫出來，這邊有觀察到什麼嗎？\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(\n",
    "         learning_rate =0.1,\n",
    "     n_estimators= 200,\n",
    "     max_depth= 20,\n",
    "     min_child_weight=6,\n",
    "     gamma=0,\n",
    "     subsample=0.8,\n",
    "     colsample_bytree=0.8,\n",
    "#      objective= '',\n",
    "#      nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27\n",
    "        )\n",
    "model.fit(X_train , Y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "rmse_rf = (mean_squared_error(Y_test , y_test_pred))**(1/2)\n",
    "\n",
    "print('RMSE test :%.3f'%rmse_rf)\n",
    "print('R square test :%.3f '%(r2_score(Y_test , y_test_pred)))\n",
    "\n",
    "\n",
    "coefs_df = pd.DataFrame()\n",
    "\n",
    "coefs_df['estimate_var'] = df.drop('price' , axis = 1).columns\n",
    "coefs_df['coefs'] = model.feature_importances_\n",
    "coefs_df = coefs_df.sort_values('coefs' , ascending = False).head(10)\n",
    "plt.figure(figsize =  (8,10))\n",
    "sns.barplot( coefs_df.coefs ,coefs_df.estimate_var , orient='h')\n",
    "plt.title('Feature importance')\n",
    "\n",
    "\n",
    "\n",
    "result = pd.DataFrame([np.exp(model.predict(X_test)) , np.exp(Y_test)]).T\n",
    "result.columns = ['predict result' , 'True result']\n",
    "result.sample(10)\n",
    "\n",
    "print('整體來看，預測值跟真實值',(result['predict result'] - result['True result']).sum())\n",
    "under_estimate = result[(result['predict result'] - result['True result']).apply(lambda x: x <0) == True].count()[0]\n",
    "print('低估的比率佔了' , round(under_estimate/len(result) , 2) * 100 , '%')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
