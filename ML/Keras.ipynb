{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\11004076\\\\Anaconda3\\\\python.exe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Appendix：手寫數字識別完整代碼(Keras2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "def load_data():  # categorical_crossentropy\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    number = 10000\n",
    "    x_train = x_train[0:number]\n",
    "    y_train = y_train[0:number]\n",
    "    x_train = x_train.reshape(number, 28 * 28)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "    x_train = x_train\n",
    "    x_test = x_test\n",
    "    x_test = np.random.normal(x_test)  # 加噪声\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    注意事项如下：\n",
    "    1、batch_size=100,epochs=20为宜，batch_size过大会导致loss下降曲线过于平滑而卡在local minima、saddle point或plateau处，batch_size过小会导致update次数过多，运算量太大，速度缓慢，但可以带来一定程度的准确率提高\n",
    "    2、hidden layer数量不要太多，不然可能会发生vanishing gradient(梯度消失)，一般两到三层为宜\n",
    "    3、如果layer数量太多，则千万不要使用sigmoid等缩减input影响的激活函数，应当选择ReLU、Maxout等近似线性的activation function(layer数量不多也应该选这两个)\n",
    "    4、每一个hidden layer所包含的neuron数量，五六百为宜\n",
    "    5、对于分类问题，loss function一定要使用cross entropy(categorical_crossentropy)，而不是mean square error(mse)\n",
    "    6、优化器optimizer一般选择adam，它综合了RMSProp和Momentum，同时考虑了过去的gradient、现在的gradient，以及上一次的惯性\n",
    "    7、如果testing data上准确率很低，training data上准确率比较高，可以考虑使用dropout，Keras的使用方式是在每一层hidden layer的后面加上一句model.add(Dropout(0.5))，其中0.5这个参数你自己定；注意，加了dropout之后在training set上的准确率会降低，但是在testing set上的准确率会提高，这是正常的\n",
    "    8、如果input是图片的pixel，注意对灰度值进行归一化，即除以255，使之处于0～1之间\n",
    "    9、最后的output最好同时输出在training set和testing set上的准确率，以便于对症下药\n",
    "    '''\n",
    "    # load training data and testing data\n",
    "    (x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "    # define network structure\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(input_dim=28 * 28, units=500, activation='relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=500, activation='relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "    # set configurations\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # train model\n",
    "    model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
    "\n",
    "    # evaluate the model and output the accuracy\n",
    "    result_train = model.evaluate(x_train, y_train)\n",
    "    result_test = model.evaluate(x_test, y_test)\n",
    "    print('Train Acc:', result_train[1])\n",
    "    print('Test Acc:', result_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Appendix：CNN in Keras2.0\n",
    "這裡還是舉手寫數字識別的例子，將單純使用DNN和加上CNN的情況作為對比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy  as  np\n",
    "from  keras . models  import  Sequential\n",
    "from  keras . layers  import  Convolution2D , MaxPooling2D , Flatten , Conv2D\n",
    "from  keras . layers . core  import  Dense , Dropout , Activation\n",
    "from  keras . optimizers  import  SGD , Adam\n",
    "from  keras . utils  import  np_utils\n",
    "from  keras . datasets  import  mnist\n",
    "​\n",
    "# categorical_crossentropy\n",
    "​\n",
    "​\n",
    "def  load_mnist_data ( number ):\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    ( x_train , y_train ), ( x_test , y_test ) = mnist . load_data ()\n",
    "    x_train = x_train [ 0 : number ]\n",
    "    y_train = y_train [ 0 : number ]\n",
    "    x_train = x_train . reshape ( number , 784 )\n",
    "    x_test = x_test . reshape ( 10000 , 784 )\n",
    "    x_train = x_train . astype ( 'float32' )\n",
    "    x_test = x_test . astype ( 'float32' )\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = np_utils . to_categorical ( y_train , 10 )\n",
    "    y_test = np_utils . to_categorical ( y_test , 10 )\n",
    "    x_train = x_train  /  255\n",
    "    x_test = x_test  /  255\n",
    "​\n",
    "    return ( x_train , y_train ), ( x_test , y_test )\n",
    "​\n",
    "​\n",
    "if  __name__ == '__main__' :\n",
    "    ( x_train , y_train ), ( x_test , y_test ) = load_mnist_data ( 10000 )\n",
    "​\n",
    "    # do DNN\n",
    "    model = Sequential ()\n",
    "    model . add ( Dense ( input_dim = 28  *  28 , units = 500 , activation = 'relu' ))\n",
    "    model . add ( Dense ( units = 500 , activation = 'relu' ))\n",
    "    model . add ( Dense ( units = 500 , activation = 'relu' ))\n",
    "    model . add ( Dense ( units = 10 , activation = 'softmax' ))\n",
    "    model . summary ()\n",
    "​\n",
    "    model . compile ( loss = 'categorical_crossentropy' ,\n",
    "                  optimizer = 'adam' , metrics =[ 'accuracy' ])\n",
    "​\n",
    "    model . fit ( x_train , y_train , batch_size = 100 , epochs = 20 )\n",
    "​\n",
    "    result_train = model . evaluate ( x_train , y_train )\n",
    "    print ( '\\nTrain Acc:\\n' , result_train [ 1 ])\n",
    "​\n",
    "    result_test = model . evaluate ( x_test , y_test )\n",
    "    print ( '\\nTest Acc:\\n' , result_test [ 1 ])\n",
    "​\n",
    "    # do CNN\n",
    "    x_train = x_train . reshape ( x_train . shape [ 0 ], 1 , 28 , 28 )\n",
    "    x_test = x_test . reshape ( x_test . shape [ 0 ], 1 , 28 , 28 )\n",
    "​\n",
    "    model2 = Sequential ()\n",
    "    model2 . add ( Conv2D ( 25 , ( 3 , 3 ), input_shape =(\n",
    "        1 , 28 , 28 ), data_format = 'channels_first' ))\n",
    "    model2 . add ( MaxPooling2D (( 2 , 2 )))\n",
    "    model2 . add ( Conv2D ( 50 , ( 3 , 3 )))\n",
    "    model2 . add ( MaxPooling2D (( 2 , 2 )))\n",
    "    model2 . add ( Flatten ())\n",
    "    model2 . add ( Dense ( units = 100 , activation = 'relu' ))\n",
    "    model2 . add ( Dense ( units = 10 , activation = 'softmax' ))\n",
    "    model2 . summary ()\n",
    "​\n",
    "    model2 . compile ( loss = 'categorical_crossentropy' ,\n",
    "                   optimizer = 'adam' , metrics =[ 'accuracy' ])\n",
    "​\n",
    "    model2 . fit ( x_train , y_train , batch_size = 100 , epochs = 20 )\n",
    "​\n",
    "    result_train = model2 . evaluate ( x_train , y_train )\n",
    "    print ( '\\nTrain CNN Acc:\\n' , result_train [ 1 ])\n",
    "    result_test = model2 . evaluate ( x_test , y_test )\n",
    "    print ( '\\nTest CNN Acc:\\n' , result_test [ 1 ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
