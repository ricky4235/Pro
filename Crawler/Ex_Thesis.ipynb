{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ex_Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "台灣博碩士論文網爬蟲\n",
    "https://tlyu0419.github.io/2020/06/07/Crawler-ndltd/#more\n",
    "因為想要做學術圈的社群網絡分析，就順手寫了博碩士論文網的爬蟲程式，以下我簡要記錄了在爬這個網站時遇到的問題與解決方式，\n",
    "並於文末附上程式，供有需要的人參考"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "當我們嘗試在博碩士論文網輸入關鍵字並送出查詢後會的看到以下的畫面，在這個畫面中，有以下幾個值得注意的事情：\n",
    "\n",
    "網址列：網址中有個ccd的參數，這是 cookie 資訊，不同的人、不同的時間進來都會不一樣，\n",
    "而我們把這個網址複製給其他人時，也會重新被導向首頁，並產生新的 Cookie。\n",
    "檢索策略：這裡有許多種查詢方式，其中簡易檢索的查詢方式有許多限制，如果我們想要查詢特定學門的所有論文，要採用指令檢索的方式查論文。\n",
    "查詢結果：查詢出的論文網址是專屬於這個 Cookie 使用的網址，複製網址給其他人並沒有辦法使用，會重新導向首頁。\n",
    "在這裡查詢出的結果如下，觀察後會發現當中有 cookie(ccd) 與 頁數(r1)的資訊。\n",
    "https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=fuy93N/record?r1=1&h1=1\n",
    "https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=fuy93N/record?r1=2&h1=1\n",
    "https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd=fuy93N/record?r1=3&h1=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://lh3.googleusercontent.com/pw/ACtC-3fxslKKYVGSGaW6Hez_IUFdsCBLL8B4RkLW0_cmqujo5pt0CqD_9V2fBpAZ7ZmT2rtJtzYMCLTOzbZ824MDF22RIsSFtGREKbIhiiYmORXkfIShD6DvE938KWO83Xn2RZ3jx9QmzXfBUZPLRDLciujE=w851-h868-no?authuser=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "另外我們如果觀察網頁的背後送的 request 中有哪些參數的話，我們會發現裡面的參數相當複雜，裡面有查詢的關鍵字，與一些不知名的參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://lh3.googleusercontent.com/pw/ACtC-3fyIiqAg5sBZBbaDujlicUI1JLLEkNO55r08oQOvBMbC4bsbNo1nIAu5Zan5bzhWbo4b9hqso3m4acJjRww4li7CsXIRpt2l3bmtJUNxSZil-wCFoYdFAPuXg2ePVQ_oRLbN-jwktgZpCuWrMoFahHX=w622-h491-no?authuser=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "考量我們要查詢的資料量並不大，而且查詢的參數也相當複雜，甚至還有加入Cookie的反爬蟲機制，\n",
    "這時候我們就直接選擇使用Selenium來解決這次的任務!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "註：最後要提醒博碩士論文網還有一個反爬蟲機制，一個 Cookie 查詢約 500 篇論文後就會被鎖Session，\n",
    "這時候我們需要關閉 Selenium 的網頁，並重新開啟網頁取得新的 Session & Cookie 繼續爬蟲任務。\n",
    "因此可以寫個簡單的 try-except 函數，當網頁請求失敗時就自動啟動!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "檢索策略：\"博士\".ty and (\"社會服務學門\" or \"社會及行為科學學門\").sglv1；檢索結果共 4205 筆資料\n",
    "\n",
    "注意事項：\n",
    "\n",
    "網址列需要送Cookie資訊\n",
    "簡單查詢一定要指定關鍵字，如果想查詢學門的資料建議用指令查詢\n",
    "論文的網址是用編號的方式，\n",
    "參數太複雜，資料量也不多，果斷使用selenium\n",
    "一定要try-except"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "收集論文清單"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://ndltd.ncl.edu.tw/')\n",
    "driver.find_element_by_xpath('//a[@title=\"指令查詢\"]').click()\n",
    "driver.find_element_by_id('ysearchinput0').send_keys('\"博士\".ty and (\"社會服務學門\" or \"社會及行為科學學門\").sglv1')\n",
    "driver.find_element_by_id('gs32search').click()\n",
    "cookie = re.findall(r'ccd=(.*?)/', driver.current_url)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while i <= 4205:\n",
    "    try:\n",
    "        print('='*80)\n",
    "        print('Dealing with ', str(i),'...')\n",
    "        info1,   info2,  info3,  info4,  info5,  info6,  info7,  info8,  info9, info10, info11, info12, info13, info14, info15, info16, info17, info18, info19, info20, info21, info22, info23, info24, info25 = ['']*25\n",
    "        driver.get('https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd={}/record?r1={}&h1=0'.format(cookie, i))\n",
    "        soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "        # 論文基本資料\n",
    "        tbody = soup.find('table',{'id':'format0_disparea'})\n",
    "\n",
    "        # 連結網址\n",
    "        url = tbody.find('input',{'id':'fe_text1'})['value']\n",
    "        print('連結網址：', url)\n",
    "\n",
    "        # 研究生\n",
    "        for element in tbody.select('tr'):\n",
    "            if '研究生' in element.text:\n",
    "                info1 = element.find('a').text\n",
    "                break    \n",
    "        print('研究生:', info1)\n",
    "\n",
    "        # 研究生_外文\n",
    "        for element in tbody.select('tr'):\n",
    "            if '研究生(外文)' in element.text:\n",
    "                info2 = element.find('a').text\n",
    "                break    \n",
    "    #     print('研究生_外文:', info2)\n",
    "\n",
    "        # 論文名稱\n",
    "        for element in tbody.select('tr'):\n",
    "            if '論文名稱' in element.text:\n",
    "                info3 = element.find('td').text\n",
    "                break    \n",
    "        print('論文名稱:', info3)\n",
    "\n",
    "        # 論文名稱_外文\n",
    "        for element in tbody.select('tr'):\n",
    "            if '論文名稱(外文)' in element.text:\n",
    "                info4 = element.find('td').text\n",
    "                break   \n",
    "    #     print('論文名稱_外文:', info4)\n",
    "\n",
    "        # 指導教授\n",
    "        for element in tbody.select('tr'):\n",
    "            if '指導教授' in element.text:\n",
    "                info5 = element.find('td').text\n",
    "                break   \n",
    "        print('指導教授:', info5)\n",
    "\n",
    "        # 指導教授_外文\n",
    "        for element in tbody.select('tr'):\n",
    "            if '指導教授(外文)' in element.text:\n",
    "                info6 = element.find('td').text\n",
    "                break   \n",
    "    #     print('指導教授_外文:', info6)\n",
    "\n",
    "        # 學位類別\n",
    "        for element in tbody.select('tr'):\n",
    "            if '學位類別' in element.text:\n",
    "                info7 = element.find('td').text\n",
    "                break   \n",
    "    #     print('學位類別:', info7)\n",
    "\n",
    "        # 校院名稱\n",
    "        for element in tbody.select('tr'):\n",
    "            if '校院名稱' in element.text:\n",
    "                info8 = element.find('td').text\n",
    "                break   \n",
    "        print('校院名稱:', info8)\n",
    "\n",
    "        # 系所名稱\n",
    "        for element in tbody.select('tr'):\n",
    "            if '系所名稱' in element.text:\n",
    "                info9 = element.find('td').text\n",
    "                break   \n",
    "        print('系所名稱:', info9)\n",
    "\n",
    "        # 學門\n",
    "        for element in tbody.select('tr'):\n",
    "            if '學門' in element.text:\n",
    "                info10 = element.find('td').text\n",
    "                break   \n",
    "    #     print('學門:', info10)\n",
    "\n",
    "        # 學類\n",
    "        for element in tbody.select('tr'):\n",
    "            if '學類' in element.text:\n",
    "                info11 = element.find('td').text\n",
    "                break   \n",
    "    #     print('學類:', info11)\n",
    "\n",
    "        # 論文出版年\n",
    "        for element in tbody.select('tr'):\n",
    "            if '論文出版年' in element.text:\n",
    "                info12 = element.find('td').text\n",
    "                break   \n",
    "    #     print('論文出版年:', info12)\n",
    "\n",
    "        # 畢業學年度\n",
    "        for element in tbody.select('tr'):\n",
    "            if '畢業學年度' in element.text:\n",
    "                info13 = element.find('td').text\n",
    "                break   \n",
    "    #     print('畢業學年度:', info13)\n",
    "\n",
    "        # 語文別\n",
    "        for element in tbody.select('tr'):\n",
    "            if '語文別' in element.text:\n",
    "                info14 = element.find('td').text\n",
    "                break   \n",
    "    #     print('語文別:', info14)\n",
    "\n",
    "        # 論文頁數\n",
    "        for element in tbody.select('tr'):\n",
    "            if '論文頁數' in element.text:\n",
    "                info15 = element.find('td').text\n",
    "                break   \n",
    "    #     print('論文頁數:', info15)\n",
    "\n",
    "        # 中文關鍵詞\n",
    "        for element in tbody.select('tr'):\n",
    "            if '中文關鍵詞' in element.text:\n",
    "                info16 = element.find('td').text\n",
    "                break   \n",
    "    #     print('中文關鍵詞:', info16)\n",
    "\n",
    "        # 外文關鍵詞\n",
    "        for element in tbody.select('tr'):\n",
    "            if '外文關鍵詞' in element.text:\n",
    "                info17 = element.find('td').text\n",
    "                break   \n",
    "    #     print('外文關鍵詞:', info17)\n",
    "\n",
    "        # 被引用\n",
    "        for element in tbody.select('tr'):\n",
    "            if '相關次數' in element.text:\n",
    "                info18 = element.findAll('li')[0].text\n",
    "                info18 = re.sub('被引用:','',info20)\n",
    "                break   \n",
    "    #     print('被引用:', info18)\n",
    "\n",
    "        # 點閱\n",
    "        for element in tbody.select('tr'):\n",
    "            if '相關次數' in element.text:\n",
    "                info19 = element.findAll('li')[1].text\n",
    "                break   \n",
    "    #     print('點閱:', info19)\n",
    "\n",
    "        # 下載\n",
    "        for element in tbody.select('tr'):\n",
    "            if '相關次數' in element.text:\n",
    "                info20 = element.findAll('li')[3].text\n",
    "                info20 = re.sub('下載:','',info20)\n",
    "                break   \n",
    "    #     print('下載:', info20)\n",
    "\n",
    "        # 書目收藏\n",
    "        for element in tbody.select('tr'):\n",
    "            if '相關次數' in element.text:\n",
    "                info21 = element.findAll('li')[4].text\n",
    "                info21 = re.sub('書目收藏:','',info21)\n",
    "                break   \n",
    "    #     print('書目收藏:', info21)\n",
    "\n",
    "        # 摘要\n",
    "        try:\n",
    "            info22 = soup.find('td',{'class':'stdncl2'}).text\n",
    "        except:\n",
    "            info22 = ''\n",
    "    #     print('摘要：', info22)\n",
    "        # 口試委員\n",
    "        for element in tbody.select('tr'):\n",
    "            if '口試委員' in element.text:\n",
    "                info24 = element.find('td').text\n",
    "                break   \n",
    "        #     print('口試委員:', info24)\n",
    "\n",
    "        # 口試委員_外文\n",
    "        for element in tbody.select('tr'):\n",
    "            if '口試委員(外文)' in element.text:\n",
    "                info25 = element.find('td').text\n",
    "                break   \n",
    "        #     print('口試委員_外文:', info25)\n",
    "\n",
    "        # 引用\n",
    "        info23 = str(soup.find('div',{'style':'padding:10px;text-align:left;'}))\n",
    "    #     print('引用：', info23)\n",
    "        ndf = pd.DataFrame([{'研究生:':info1,\n",
    "                             '研究生_外文':info2,\n",
    "                             '論文名稱':info3,\n",
    "                             '論文名稱_外文:':info4,\n",
    "                             '指導教授':info5,\n",
    "                             '指導教授_外文':info6,\n",
    "                             '口試委員':info24,\n",
    "                             '口試委員_外文':info25,                         \n",
    "                             '學位類別':info7,\n",
    "                             '校院名稱':info8,\n",
    "                             '系所名稱':info9,\n",
    "                             '學門':info10,\n",
    "                             '學類':info11,\n",
    "                             '論文出版年':info12,\n",
    "                             '畢業學年度':info13,\n",
    "                             '語文別':info14,\n",
    "                             '論文頁數':info15,\n",
    "                             '中文關鍵詞':info16,\n",
    "                             '外文關鍵詞':info17,\n",
    "                             '相關次數':info18,\n",
    "                             '點閱':info19,\n",
    "                             '下載':info20,\n",
    "                             '書目收藏':info21,\n",
    "                             '摘要':info22,\n",
    "                             '引用':info23,\n",
    "                             '連結網址':url}])\n",
    "        df.append(ndf)\n",
    "        i += 1\n",
    "    except:\n",
    "        driver.close()\n",
    "        sleep(2)\n",
    "        driver = webdriver.Chrome()\n",
    "        sleep(1)\n",
    "        driver.get('https://ndltd.ncl.edu.tw/')\n",
    "        sleep(5)\n",
    "        driver.find_element_by_xpath('//a[@title=\"指令查詢\"]').click()\n",
    "        sleep(1)\n",
    "        driver.find_element_by_id('ysearchinput0').send_keys('\"博士\".ty and (\"社會服務學門\" or \"社會及行為科學學門\").sglv1')\n",
    "        driver.find_element_by_id('gs32search').click()\n",
    "        sleep(3)\n",
    "        cookie = re.findall(r'ccd=(.*?)/', driver.current_url)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(df, ignore_index=True).to_excel('./shuoboshilunwen.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(df, ignore_index=True).to_pickle('./shuoboshilunwen.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinct by 學門校系\n",
    "df2 = pd.concat(df, ignore_index=True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp = df2.groupby(['校院名稱','系所名稱','學類','學門']).size().reset_index()\n",
    "tmp.columns = ['學類', '學門', '校院名稱', '系所名稱', '則數']\n",
    "tmp.to_excel('校系學門學類.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "台灣博碩士論文網爬蟲v2\n",
    "https://tlyu0419.github.io/2020/06/07/Crawler-ndltd2/#more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "前幾天記錄了一篇完全透過 Selenium 來爬博碩士論文網的文章 台灣博碩士論文網爬蟲，但有沒有辦法透過 requests 更快速的完成呢?\n",
    "這篇簡單記錄了如何透過 request 的 post來保存當前的 Session，再藉由這個 Session 的狀態來 get 我們需要的資料，\n",
    "另方面也優化部分的程式碼，讓程式變得更簡潔些!\n",
    "\n",
    "如同前一篇文章所述的內容，博碩士論文網會記錄你的 Session 資訊，因此當我們把連結的網址給別人時，\n",
    "別人並沒有辦法看到我們轉貼的文章，只會被重新導回首頁 Orz…\n",
    "\n",
    "同樣的邏輯，我們如果只是單純的 get 特定的網址也沒辦法取得需要的資訊，所以我們要先開一個Session，\n",
    "並 post 查詢的參數到對方的伺服器，讓對方記得我們，然後再用這個 Session 去 get 我們需要的資料。\n",
    "\n",
    "怎麼做呢?其實並不能，我們首先觀察瀏覽器 post 過去的資料，並且把這些資料透過 python 送到對方的伺服器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "收集論文清單"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "r1 = 1\n",
    "while r1 <= 4207:\n",
    "    columns = []\n",
    "    values = []\n",
    "    try:\n",
    "        res2 = rs.get('https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd={}/record?r1={}&h1=1'.format(cookie, r1))\n",
    "        soup = BeautifulSoup(res2.text)\n",
    "        for i in soup.find('table', {'id':'format0_disparea'}).findAll('tr'):\n",
    "            if 'std1' in str(i):\n",
    "#                 print(i.find('th',{'class':'std1'}).text)\n",
    "                columns.append(i.find('th',{'class':'std1'}).text)\n",
    "#                 print(i.find('td',{'class':'std2'}).text)\n",
    "                values.append(i.find('td',{'class':'std2'}).text)\n",
    "        \n",
    "        # 永久網址\n",
    "        columns.append('永久網址')\n",
    "        try:\n",
    "            permanent = soup.find('input',{'id':'fe_text1'})['value']\n",
    "        except:\n",
    "            permanent = ''\n",
    "        values.append(permanent)\n",
    "        \n",
    "        \n",
    "        # 摘要\n",
    "        columns.append('摘要')\n",
    "        try:\n",
    "            abst = soup.find('td',{'class':'stdncl2'}).text\n",
    "        except:\n",
    "            abst = ''\n",
    "        values.append(abst)\n",
    "#         print('摘要：', abst)\n",
    "        \n",
    "        # 引用\n",
    "        columns.append('引用')\n",
    "        try:\n",
    "            Quote = str(soup.find('div',{'style':'padding:10px;text-align:left;'}))\n",
    "        except:\n",
    "            Quote = ''\n",
    "        values.append(Quote)\n",
    "#         print('引用：', Quote)\n",
    "        \n",
    "        ndf = pd.DataFrame(data=values, index=columns).T\n",
    "        print('論文名稱：',ndf['論文名稱'])\n",
    "        print('永久網址：', ndf['永久網址'])\n",
    "        df.append(ndf)\n",
    "        r1 += 1  \n",
    "        print('='*88)\n",
    "    except:\n",
    "        # Cookie 失效時自動重啟 Selenium 取得新的 Cookie，並更新參數\n",
    "        print('Get New Cookie')\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get('https://ndltd.ncl.edu.tw/')\n",
    "        sleep(2)\n",
    "        driver.find_element_by_xpath('//a[@title=\"指令查詢\"]').click()\n",
    "        sleep(2)\n",
    "        driver.find_element_by_id('ysearchinput0').send_keys('\"博士\".ty and (\"社會服務學門\" or \"社會及行為科學學門\").sglv1')\n",
    "        sleep(0.5)\n",
    "        driver.find_element_by_id('gs32search').click()\n",
    "        sleep(2)\n",
    "        cookie = re.findall(r'ccd=(.*?)/', driver.current_url)[0]\n",
    "        driver.close()\n",
    "        headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "                 'Cookie': 'ccd={}'.format(cookie)}\n",
    "        \n",
    "        payload = {'qs0': '\"博士\".ty and (\"社會服務學門\" or \"社會及行為科學學門\").sglv1',\n",
    "                   'qf0': '_hist_',\n",
    "                   'gs32search.x': '27',\n",
    "                   'gs32search.y': '9',\n",
    "                   'displayonerecdisable': '1',\n",
    "                   'dbcode': 'nclcdr',\n",
    "                   'action':'',\n",
    "                   'op':'',\n",
    "                   'h':'',\n",
    "                   'histlist':'',\n",
    "                   'opt': 'm',\n",
    "                   '_status_': 'search__v2'}\n",
    "        \n",
    "        rs = requests.session()\n",
    "        res = rs.post('https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/ccd={}/search'.format(cookie),data=payload, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df, ignore_index=True)\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./博碩士論文.pickle')\n",
    "df.to_excel('./博碩士論文.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df2.groupby(['校院名稱','系所名稱','學類','學門']).size().reset_index()\n",
    "tmp.columns = ['學類', '學門', '校院名稱', '系所名稱', '則數']\n",
    "tmp.to_excel('校系學門學類.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "最後大家會問說，那麼 Cookie 要怎麼來?超過查詢數量的限制怎麼辦?\n",
    "這時候我們與其花時間去研究/破解 Cookie 的生成方式，不如直接開個 Selenium 直接取結果會更有效益!\n",
    "畢竟我們最想要節省的時間是中間在抓上千、萬篇論文資料時，頁面切換的時間，語法如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://ndltd.ncl.edu.tw/')\n",
    "sleep(2)\n",
    "driver.find_element_by_xpath('//a[@title=\"指令查詢\"]').click()\n",
    "cookie = re.findall(r'ccd=(.*?)/', driver.current_url)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
