{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 網頁的編碼大略上可以分成兩類，ANSI，Unicode\n",
    "utf-8和big-5都是中文常用的編碼。如果你看一些很古早的網站(大概是20年前)，中文很多都是big-5編碼，現在因為都是用utf-8。所以有時候瀏覽一些中文網站變成亂碼的時候，它很可能是用big-5編碼，那如果你把編碼轉成big-5以後，應該就會正常顯示了。也就是說，如果那個網站還在用big-5的話，有可能十幾二十年都沒有再維護了，資料也可能很舊了，因為我們現在的話中文都是用utf-8編碼。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSI(如BIG5,GBXXXX) :\n",
    "Big5僅是ANSI的其中一種編碼方式，支援約16000個繁體中文， 可應付大多文書工作，不過若是遇到罕見字，也無法支援，如: 「犇」「鱻」「堃」\n",
    "\n",
    "Big 5:\n",
    "1. 每個中文字使用 2 bytes\n",
    "2. 部分文字用到了控制碼 所以許多程式與軟體都會有許、蓋、功這類中文字的沖碼問題\n",
    "3. 延伸字集中，有簡體字但是沒有定義日文字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicode(UTF-8, UTF-16)：\n",
    "UTF-8 :\n",
    "1. 採用變動大小，中文字使用 3 bytes，英文則維持 1 byte 因此若轉碼後，資料庫整體會變成 1.5 倍大，200MB(Big5) -> 300MB(UTF-8)\n",
    "2. 支援所有語言文字，還有一些怪怪圖形\n",
    "3. 簡體與正體中文重複字只定義一次，例如說，簡體的”山”，跟正體的”山” 是同一個 UTF-8 編碼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看目標網頁的編碼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有時候我們爬的網頁可能不是使用UTF-8編碼的, 這時候就需要在程式裡面處理編碼的問題.<br>\n",
    "那要怎麼看目標網頁的編碼呢? 其實只要透過developer tool觀看網頁的head部分即可, 在head區塊裡, 找到meta標籤, 其中的charset就是該網頁的編碼了, 譬如說以下就是用UTF-8編碼的網頁:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<meta charset=\"UTF-8\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非UTF-8編碼的處理\n",
    "若你要爬的網頁, 其編碼不是UTF-8, 就必須在程式裡面處理了, 接下來的範例會示範怎麼做這件事.\n",
    "至於不同的文件類型, 除了html外, 也許你有一天也會碰上xml, 那這時候就可以選用可處理xml的library去處理其內容.\n",
    "\n",
    "這邊的範例會去爬兩張非UTF-8編碼的網頁, 其中, 在取得response的時候, 就可以先指定原文件的編碼, 方式如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表示爬回來的網頁內容是以BIG-5編碼為基礎的\n",
    "resp.encoding = 'big5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後, 在處理完資料然後要儲存成檔案時, 再轉換成UTF-8編碼:<br>\n",
    "這樣最後儲存的結果就會是UTF-8編碼了."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xxx.txt', 'w', encoding='UTF-8') as file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<meta http-equiv=\"content-type\" content=\"text/html;charset=gbk\">\n",
    "<meta charset=\"utf-8\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title 网页出现乱码，浏览器字体问题。\n",
      "content 打开网页全是乱码，点击查看-编码，没有字体可以选择，只有两个选项“从左到右的文档”“从右到左的文档”。点击“Internet选项”，然后点击：“字体”，没有反应。请问怎么办？...\n",
      "==============================================\n",
      "跟任何人都可以用英文聊天：1天1堂英文課，30天融入老外生活圈【虛擬點讀筆版】(附防水書套+超實用必備聊天句300口袋書+1虛擬點讀筆APP+1CD)\n",
      "一人公司起步的思維與挑戰\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def baidu_encoding():\n",
    "    resp = requests.get('https://zhidao.baidu.com/question/48795122.html')\n",
    "    resp.encoding = 'gbk'  #\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    title = soup.find('span', 'ask-title').text.strip()\n",
    "    content = soup.find('span', 'con').text.strip().replace('\\n', '')\n",
    "    print('title', title)\n",
    "    print('content', content)\n",
    "    try:\n",
    "        with open(title + '.txt', 'w', encoding='UTF-8') as file:\n",
    "            file.write(content)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def gold_66_encoding():\n",
    "    resp = requests.get('http://www.books.com.tw/activity/gold66_day/')\n",
    "    resp.encoding = 'utf-8' #目前已經從big5改為utf-8\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    books = list()\n",
    "    for div in soup.find_all('div', 'mod-04 clearfix'):\n",
    "        books.append(div.h4.text)\n",
    "    print('\\n'.join(books))\n",
    "    try:\n",
    "        with open('66.txt', 'w', encoding='UTF-8') as file:\n",
    "            file.write('\\n'.join(books))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    baidu_encoding()\n",
    "    print(\"==============================================\")\n",
    "    gold_66_encoding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML文件\n",
    "這邊用的是ElementTree.XML套件:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'example.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7141121ab3ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'example.xml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrib\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\xml\\etree\\ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(source, parser)\u001b[0m\n\u001b[0;32m   1195\u001b[0m     \"\"\"\n\u001b[0;32m   1196\u001b[0m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1197\u001b[1;33m     \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1198\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\xml\\etree\\ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, source, parser)\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[0mclose_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m             \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m             \u001b[0mclose_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'example.xml'"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tree = ET.parse('example.xml')\n",
    "    root = tree.getroot()\n",
    "    print(root.attrib)\n",
    "    total = root.attrib['totalResults']\n",
    "    movies = list()\n",
    "    for tag in root.findall('result'):\n",
    "        print(tag.attrib)\n",
    "        movies.append(tag.attrib['title'])\n",
    "    print('-----')\n",
    "    print('There are', total, 'results in the xml file.')\n",
    "    print('Top 10 record:')\n",
    "    print('\\n'.join(movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
