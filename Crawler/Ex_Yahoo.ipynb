{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ex_Yahoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yahoo奇摩電影本週新片(第一頁)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yahoo電影也算滿好爬的, 這邊要做的事情是把本週新片及其相關資訊都列出來, 並且寫入json檔案裡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'expectation': '\\n                    76%\\n                    網友想看\\n                  ', 'ch_name': '\\n                  愛情人形', 'en_name': '\\n                    Romance Doll', 'release_date': '2020-02-14', 'intro': '                                  他深愛妻子，所以對她說了謊她深愛丈夫，所以對他隱瞞了秘密哲雄（高橋一生 飾）大學雕塑學系畢業後，意外來到一家情趣用品公司，負責「情趣人偶」的設計。為了讓人偶更接近真實，他謊稱醫學研究人員，為了製作義乳，找來人體模特兒製作乳房的模型。哲雄對美麗的女模園子（蒼井優 飾）一見鍾情，兩人很快地步入禮堂，然而直到婚後，哲雄始終無法對妻子坦承：他的職業是情趣人偶設計師。儘管兩人的生活表面上平靜、幸福，但隨著哲雄愈來愈投入工作，他對園子的熱情和慾望卻也愈來愈減低，連帶著性生活次數也減少了。當兩人的婚姻面臨危機之際，園子對丈夫的秘密再也隱瞞不住……。電影改編自導演棚田由紀的原作同名小說，自2008年在雜誌《達．芬奇》上連載，講述主角哲雄隱瞞妻子自己真實的職業，沉溺於製作情趣人偶的工作中，導致與妻子的感情出現裂縫的故事，故事探討夫妻間的性愛關係、日常相處等議題，找來實力派高人氣演員蒼井優、高橋一生相隔18年再度同台演出，話題性十足！【關於電影】高橋一生、蒼井優 相隔十八年再度共演 激情演出夫妻之愛本片改編自導演棚田由紀的同名小說，講述主角哲雄隱瞞妻子真實的職業，沉溺於製作充氣娃娃的工作中，導致與妻子的感情出現裂縫的故事，故事除了標榜探討夫妻間的性愛關係、日常相處等話題性十足的議題，更找來實力派高人氣演員蒼井優、高橋一生相隔18年再度同台演出。男主角高橋一生表示自己在讀劇本時，就對其中純粹的愛戀心意，被以具有電影感的方式描繪出來，感到相當驚艷！高橋一生形容：「這個作品也並非用一種激烈的方式去描繪男女關係，反倒是在淡淡的日常生活中，漸漸去看見那個真正的愛究竟為何，某種程度來說，是一種達到了最高境界的作品。」而飾演高橋一生的妻子，且在現實生活中也才剛升格為人妻不久的蒼井優，則是繼《她不知道那些鳥的名字》、《男人真命苦 電影版》後，再度大尺度演出，蒼井優表示：「我一直很希望能夠再與棚田導演合作，所以這麼棒的故事，我實在沒有拒絕的理由。我和高橋一生先生，雖然曾一起參與過電視連續劇的演出，但如此紮實的對手戲，應該是從《青春電幻物語》之後就再也沒有過了。」片中兩人除了激情床戲外，更有多場唯美的戀愛場景，像是一起在櫻花紛飛的公園吃便當、一起開心笑著手牽手走在街頭等鏡頭，娓娓道出兩人平凡地深愛彼此的模樣。女導演棚田由紀細膩、大膽刻劃「情趣娃娃」職人精神由於高橋一生此次飾演的角色職業為「情趣娃娃設計師」，因此在開拍前特別前往製作情趣娃娃的工廠見習，學習關於情趣娃娃製作的相關事項，讓高橋一生大開眼界：「工廠裡的每位員工，完完全全就是一種職人的概念，他們是用一種美術工藝的心態去製造每一件作品。看見他們那樣的身影，讓我也能夠順利調整心態，去飾演哲雄這個角色。」而本片導演兼原著作者的棚田由紀則表示，自己大約15年前就知道情趣娃娃的存在，並為它的高品質和美麗而感到震驚，進而決定開始構思這個故事。「因為我一直很欽佩這些做娃娃的工匠，所以我想透過寫一個關於他們的故事來傳達我的驚艷。同時，我想刻劃一對夫婦的相處，描寫情趣娃娃工匠在情趣娃娃和愛妻之間搖擺的情慾關係。」棚田由紀也坦言，當年小說出版時，那個時代仍然對這樣的主題持懷疑態度，接受度並不高，直到近期某一次澀谷的一家畫廊舉行了一場關於情趣娃娃的展覽，當時大排長龍的景象成了一個熱門話題，排隊人潮中還有不少年輕女性，認真欣賞著娃娃的美。「當時我看到這幅景象，便覺得時候到了！可以將這個故事拍成電影，帶到觀眾的面前，我也很快地決定由高橋一生擔綱主演。這部電影能在小說問世十年後出現，真是太好了！」                              '}\n",
      "{'expectation': '\\n                    88%\\n                    網友想看\\n                  ', 'ch_name': '\\n                  尋愛夢工廠', 'en_name': '\\n                    Traumfabrik', 'release_date': '2020-02-14', 'intro': '                                  ★《布達佩斯大飯店》《美國隊長：英雄內戰》製片團隊動人打造★1961年設立柏林圍牆前夕，一段如童話般的愛情故事就此展開…★2019 德國金母雞獎最佳女主角艾米爾（丹尼斯莫賈 飾）是名懷抱夢想、天不怕地不怕的臨時演員，在某次與法國女明星米露（艾米莉亞舒勒 飾）對戲後，從此對她一見鍾情，兩人就此陷入愛河，不料德國此時卻政局動盪，柏林圍牆興建在即，兩人被迫分離…米露選擇離開德國，前往法國展開新生活，始終對米露念念不忘的艾米爾，又該如何突破種種困難，再次與米露重逢呢？                              '}\n",
      "{'expectation': '\\n                    80%\\n                    網友想看\\n                  ', 'ch_name': '\\n                  謎夜拼圖', 'en_name': '\\n                    Only The Animals', 'release_date': '2020-02-14', 'intro': '                                  ★坎城金棕櫚提名導演 多米尼克摩爾新作★非線性敘事手法，懸疑精彩、引人入勝★繼《記憶拼圖》《黑色追緝令》再度令人讚嘆的傑作★威尼斯影展之威尼斯日最佳影片提名★東京影展最佳女主角獎媲美《黑色追緝令》情節步步翻轉、如《記憶拼圖》抽絲剝繭般的敘事手法；不到最後一刻，無法拼湊真相全貌！一場暴風雪覆蓋了通往法國偏遠小鎮的道路，一台空車停在路邊，車主卻不知去向。當地警方來到了小鎮農場主人米歇爾的家中問話，米歇爾卻顯不耐；女主人艾莉絲一面對失踪事件感到好奇，但同時她更掛念著她的保險客戶約瑟夫。年輕貌美的服務生瑪莉詠在餐廳邂逅了謎一般的伊芙琳，兩人很快陷入熱戀。雖然年齡差距和身份地位都阻擋她們在一起，但瑪莉詠靠著伊芙琳留下的隻字片語，花了好幾天徒步走到伊芙琳的家門前。然而等待她的卻不再是床上滿口愛意的那個人。看似意外的小鎮事故卻如蝴蝶效應般影響著來自不同地方的人們，一個不寧靜的夜晚意外串接起所有人心裡最深層的秘密。                              '}\n",
      "{'expectation': '\\n                    94%\\n                    網友想看\\n                  ', 'ch_name': '\\n                  全境失控', 'en_name': '\\n                    AI Amok', 'release_date': '2020-02-14', 'intro': '                                  ★《第22年的告白：我是殺人犯》製作團隊年度科幻力作！★《第22年的告白：我是殺人犯》票房名導入江悠，驚悚詮釋科技未來！★ 日本豪華演技派陣容，共同演繹人工智能失控危機！★「日劇女王」松嶋菜菜子五度攜手「魅力熟男」大澤隆夫，共同詮釋夫妻檔！從今開始，科技掌握你的生死2030年的日本，支撐人類生活的人工智能「希望」開發者桐生浩介（大澤隆夫飾演），由於成就獲得肯定，讓他帶著女兒重返久違的日本。當桐生受到英雄般的盛大歡迎時，「希望」卻突然全面失控，甚至開始以合理與否，來決定人類的生存價值，並對無生存價值的民眾展開殺戮。警察廳天才搜查官櫻庭（岩田剛典飾演），一口咬定桐生是讓「希望」失控的恐怖份子，並透過密佈在全日本的監視網，追捕展開逃亡的桐生。另一方面，「希望」的管理負責人西村（賀來賢人飾演），也為了澄清桐生的清白而四處奔走；轄區資深刑警合田（三浦友和飾演）與搜查一課菜鳥刑警奧瀨（廣瀨愛麗絲飾演）也積極調查。當日本陷入一片混亂之際，拼死逃亡的桐生，能否證明自己的清白？而又是什麼原因，造成「希望」的全面失控呢？【關於電影】《第22年的告白：我是殺人犯》製作團隊年度科幻力作集結日本豪華演技派卡司，被譽為2020年日本年度科幻力作的《全境失控》，將時空描準在10年後的近未來日本，劇情聚焦在目前於日本逐漸擴大的人工智能使用，以及它在生活面的普及。不過，一旦人工智能發展到一定高度，反過來開始攻擊人類，甚至還有能力操控人類的生死，那又會是什麼樣的情景？而背負著人工智能失控的天才科學家製造者，又該如何在密佈全日本的監視網中，展開證明自己清白的大逃亡呢？本片是曾打造出《第22年的告白：我是殺人犯》製作團隊的年度科幻力作，也是製作人北島直明繼《第22年的告白：我是殺人犯》之後，再度與導演入江悠合作。入江導演對這次的製作表示：「我以前就想拍『以近未來為舞台的科幻電影』，我本身也是獨立製片導演出身，以預算和規模來說，這一直是想拍卻拍不了的類型，沒想到總算能得到這樣的機會。當下我們就討論到，要以人工智能為主題去拍攝。」兩人也懷抱本片必須是「全原創作品」的共識，在這種前提下，去挑戰日本電影一向不擅長的「近未來科幻片」。製片人北島笑說：「當下我實在覺得，這真是有勇無謀的挑戰。」導演也表示：「真的感受到無比壓力。」為了實踐已經開始著手的企劃，製片人還親自前往史蒂芬史匹柏（Steven Spielberg）與喬治盧卡斯（George Lucas）等名導人才輩出的南加州大學視察，只為了更加瞭解「人工智能」這個主題，他並補充：「真要說的話，人工智能的電影主題已經很廣泛了，像是《銀翼殺手》（Blade Runner）、《魔鬼終結者》（The Terminator），好萊塢幾乎把這種題材都拍完了，所以我想透過這部作品，向觀眾提出「人類是否已經成熟到可以掌控人工智能了呢？」這項問題。導演也補充：「我希望本片能對今後的未來有所提示，也想打造出日本人工智能相關題材電影的金字塔。」尤其劇組對「2030年未來的預測」煞費苦心，努力廣召各領域專家協助監修，徹底追求達到真實感，並將實際上厚生勞働省公佈的「超高齡」及「超少子化」的十年後預測數值，以及假想在最糟情況下的日本經濟狀況，都一一列入劇本當中。意識到現實中有可能會成真的嚴峻未來，還特別找來許多臨時演員來飾演老人或流浪漢等等，完全以「挑戰」的角度來打造這部作品。導演也找來大澤隆夫領銜主演，再加上賀來賢人、岩田剛典、廣瀨愛麗絲、玉城蒂娜、松嶋菜菜子、三浦友和等代表日本電影界的豪華演員齊聚一堂，共同打造出這部全原創的科幻驚悚力作。                              '}\n",
      "{'expectation': '\\n                    57%\\n                    網友想看\\n                  ', 'ch_name': '\\n                  就愛斷捨離', 'en_name': '\\n                    Happy Old Year', 'release_date': '2020-02-14', 'intro': '                                  ★ 《模犯生》天才少女「小琳」魅力再度征服大銀幕★ 《把哥哥退貨可以嗎》廢柴哥哥「桑尼」化身天菜前男友★ 2020情人節最怦然心動之作★ 不需要的東西可以說丟就丟 但回憶丟得掉嗎？★ 每個人都值得 好好說再見★ 回憶斷捨離 把愛還給你 揮別過去 心的傷疤從此痊癒設計師小琴（茱蒂蒙瓊查容蘇因 飾）想把家改造成極簡風，把不再讓她怦然心動的東西通通丟棄。整理過程中她找到很多紀念品，塵封的回憶因此重起漣漪。其中前男友（桑尼蘇莞門坦諾 飾）送的相機勾起了她的複雜情緒。抱著不告而別的愧疚多年，小琴發現她始終無法釋懷自己的自私，於是她決定鼓起勇氣歸還前男友相機，以及他們的美好回憶…                              '}\n",
      "{'expectation': '\\n                    87%\\n                    網友想看\\n                  ', 'ch_name': '\\n                  超＂人＂氣動物園', 'en_name': '\\n                    Secret Zoo', 'release_date': '2020-02-14', 'intro': '                                  ★《雞不可失》製作團隊神爆笑新作★百變演員 安宰弘 × 國民女神 姜素拉首度合作療癒溫馨喜劇\\u3000★沒有動物的動物園照樣能吸引人潮？！什麼妙計讓動物園起死回生別害怕！毫無破綻！穿上動物裝就抬頭挺胸！太洙（安宰洪 飾）在一家知名律師事務所擔任臨時職位，他夢想有一天能正式在此任職。太洙每天都要花費許多的時間以達成他的目標，某天一個難得的機會降臨在他眼前：重振一家即將停業的動物園。但這動物園裡卻已經沒有任何動物了……因此太洙想到了一個妙計，他決定讓動物園的職員們一起扮成動物面對前來的遊客！這奇招讓動物園重新吸引遊客上門，並且還在網路上造成話題，這也讓太洙有機會得到律師事務所正式的職位。不過太洙卻發現，動物園將面臨前所未有的危機……究竟他該如何挽回局面呢？                              '}\n",
      "{'expectation': '\\n                    64%\\n                    網友想看\\n                  ', 'ch_name': '\\n                  失控少年兵團', 'en_name': '\\n                    Monos', 'release_date': '2020-02-14', 'intro': '                                  ★美國權威影評網站《Indiewire》2019 年度19 大電影排行榜票選第三名★全球電影權威新聞評論媒體《銀幕》（Screen International）雜誌票選TOP5總得分第一名!★英國廣播公司BBC精選2019年度26部佳片之一★2019新墨西哥影評人紀錄片最佳外語片第二名★爛番茄99% 高分推薦！★哥倫比亞、美國、德國、阿根廷荷蘭、瑞典、烏拉圭、瑞士、丹麥９國聯合製作\\u3000榮獲國際 24 項大獎． 59 項提名游擊隊少年們在山區基地看守俘虜，擦槍走火演變成分崩離析的故事…《失控少年兵團》(Monos)講述 8 個哥倫比亞游擊隊少年在山區看守一名美國俘虜，然而轟炸機的伏擊，令事件變得複雜的故事。在拉丁美洲一座與世隔絕的山丘上，駐守著八位少年兵，在這個現代文明無法涉足的蠻荒之地，他們建立起屬於自己的儀式和生活，接受軍事操練及勞動的同時，也放縱狂歡。來自「組織」的長官傳來命令，指示他們看守美國俘虜與一頭乳牛，但不經意地一聲槍響，卻讓團體開始分崩離析。面對戰爭烈火延燒，暴力與死亡的陰影投射在他們稚嫩的心靈與軀體，他們被迫進入叢林，面對真正的恐懼……。人類在原始自然中逐一顯現的野蠻和力量在完全媲美好萊塢的攝影、剪接、表演水準上，卻沒落入英雄主義的窠臼叢林大河與雲霧丘陵交織的磅礡格局，電子音樂注入迷亂奇幻，猶如《現代啟示錄》的瘋狂加上《蒼蠅王》的殘酷，讓本片成為當代少見刻劃戰爭與人性的野心之作。聚焦於戰火邊緣的人物，描繪少年少女們是如何受到恐懼與暴力的影響，開始扭曲、腐敗甚至獸化，回到弱肉強食的原始秩序。而他們坦露出來的殘酷與陰暗，令人毛骨悚然之餘，也陷入對人類本質的思考。                              '}\n",
      "{'expectation': '\\n                    80%\\n                    網友想看\\n                  ', 'ch_name': '\\n                  殺不了的他與死不了的她', 'en_name': \"\\n                    He won't kill, She won't die\", 'release_date': '2020-02-14', 'intro': '                                  ★ 浪漫神片唯一首選！2020情人節約會必看！★ 日本Twitter年度話題No.1！史上最催淚四格漫畫躍上大銀幕！★ 日本觀眾評價高達91%催淚度，激推：「必定哭著走出戲院…」★ 《跳耀吧！時空少女》奧華子親作詞作曲，溫暖獻唱電影主題曲！總是把「殺了你」掛在嘴邊，對任何事都毫無興趣的高中生小坂（間宮祥太朗 飾），有天遇到一個正在埋葬蜜蜂屍體的鹿野（櫻井日奈子 飾），這個愛將「好想死」當作口頭禪，經常割腕自殘卻又重視昆蟲生命的邊緣女孩引起了小坂的興趣，一個遭全班排擠自殘女遇上一位對生活毫無興趣的厭世男，這對充滿反差的少男少女將會碰撞出甚麼樣的火花呢？                              '}\n",
      "{'expectation': '\\n                    87%\\n                    網友想看\\n                  ', 'ch_name': '\\n                  戰慄魔胎', 'en_name': '\\n                    Housewife', 'release_date': '2020-02-14', 'intro': '                                  鬼才導演肯艾弗諾繼《煉獄迷宮》後又一血腥邪門懼作★ 2017 巴黎怪奇影展★ 2017 西班牙錫切斯奇幻影展★ 2017 Monster Fest 澳洲恐怖電影節最佳導演★ 血色瀰漫的義大利邪典電影風格令人坐立不安★ 性愛、血漿、邪教，缺一不可的洛氏恐怖元素，向大師洛夫克拉夫特致敬！荷莉年幼時目睹了姊姊和父親被她精神異常的母親謀殺而死。二十年後，荷莉長大結了婚，幼時創傷的陰影和單調的生活讓她時時感到孤單。某日，她與丈夫受朋友的邀請，參加一個神秘組織舉辦的聚會，組織的領袖一見到荷莉便對她格外關照，從此她的生活愈發異常古怪......                              '}\n",
      "{'expectation': '\\n                    98%\\n                    網友想看\\n                  ', 'ch_name': '\\n                  雨天．紐約', 'en_name': '\\n                    A Rainy Day in New York', 'release_date': '2020-02-14', 'intro': '                                  蓋茲比（提摩西夏勒梅飾）的女友艾希莉（艾兒芬妮飾）因學校作業爭取到親赴曼哈頓訪談知名大導演羅蘭波拉德 （李佛薛伯飾）的機會，於是蓋茲比計畫了一場充滿紐約復古風情的浪漫約會，但艾希莉卻被導演約去看電影，接 著又遇見了金牌編劇泰德戴杜夫（裘德洛飾）與大明星法蘭西斯柯維嘉（狄亞哥盧納），導致蓋茲比的約會計畫泡 湯。當艾希莉在三個才華洋溢的男人之間打轉時，蓋茲比和前女友的妹妹千兒（賽琳娜戈梅茲飾）意外一「吻」也 打亂了他的心…                              '}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "Y_MOVIE_URL = 'https://tw.movies.yahoo.com/movie_thisweek.html'\n",
    "\n",
    "Y_MOVIE_INFO_URL = 'https://tw.movies.yahoo.com/movieinfo_main.htm'\n",
    "Y_MOVIE_PHOTO_URL = 'https://tw.movies.yahoo.com/movieinfo_photos.html'\n",
    "Y_MOVIE_TIME_URL = 'https://tw.movies.yahoo.com/movietime_result.html'\n",
    "\n",
    "\n",
    "def get_web_page(url):\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        print('Invalid url: ', resp.url)\n",
    "        return None\n",
    "    else:\n",
    "        return resp.text\n",
    "\n",
    "\n",
    "def get_movies(dom):\n",
    "    soup = BeautifulSoup(dom, 'html5lib')\n",
    "    movies = []\n",
    "    rows = soup.find_all(\"div\", class_=\"release_info_text\")  #首先取出所有此分頁的本周新片\"資訊\"(文字框)，此為複數個\"資訊\"(div)\n",
    "    for row in rows:\n",
    "        movie = dict()\n",
    "        movie['expectation'] = row.find('div', 'leveltext').text\n",
    "        movie['ch_name'] = row.find('div', 'release_movie_name').a.text\n",
    "        movie['en_name'] = row.find('div', 'en').a.text\n",
    "        #movie['movie_id'] = get_movie_id(row.find('div', 'release_foto').a['href'])  #這在海報部份，不在find_all範圍\n",
    "        #movie['poster_url'] = row.find('div', 'release_foto').img['src']             #這在海報部份，不在find_all範圍\n",
    "        movie['release_date'] = get_date(row.find('div', 'release_movie_time').text)\n",
    "#不懂:網頁沒有顯示\"...詳全文\"之後的文字，但卻全爬出來========================================================================\n",
    "        movie['intro'] = row.find('div', 'release_text').text.replace(u'...詳全文', '').replace('\\n', '').replace('\\xa0', '')\n",
    "        #movie['trailer_url'] = row.find('div', 'release_btn color_btnbox').a['href']   #這在海報部份，不在find_all範圍\n",
    "        movies.append(movie)\n",
    "    return movies\n",
    "\n",
    "\n",
    "def get_date(date_str):\n",
    "    # e.g. \"上映日期：2017-03-23\" -> match.group(0): \"2017-03-23\"\n",
    "    pattern = '\\d+-\\d+-\\d+'\n",
    "    # re.compile API DOC: https://docs.python.org/3/library/re.html#re.compile\n",
    "    # re.search API DOC: https://docs.python.org/3/library/re.html#search-vs-match\n",
    "    match = re.search(pattern, date_str)\n",
    "    if match is None:\n",
    "        return date_str\n",
    "    else:\n",
    "        return match.group(0)\n",
    "\n",
    "\n",
    "def get_movie_id(url):  #id在網href後面\n",
    "    # e.g. \"href=\"https://movies.yahoo.com.tw/movieinfo_main/%E5%85%A8%E5%A2%83%E5%A4%B1%E6%8E%A7-ai-amok-10426\"\"\n",
    "    #      id=10426\"\n",
    "    try:\n",
    "        movie_id = url.split('-')[-1]  # 以'-'拆開，取最後，也就是\"10426\"\n",
    "    except:\n",
    "        movie_id = url\n",
    "    return movie_id\n",
    "\n",
    "\n",
    "def get_complete_intro(movie_id):\n",
    "    page = get_web_page(Y_MOVIE_INFO_URL + '/id=' + movie_id)\n",
    "    if page:\n",
    "        \n",
    "        soup = BeautifulSoup.get(page, 'html5lib')\n",
    "        div_text_show = soup.find('div', 'text show')\n",
    "        if div_text_show:\n",
    "            print(div_text_show.text)\n",
    "        div_text_full = soup.find('div', 'text full')\n",
    "        if div_text_full:\n",
    "            print(div_text_full.text)\n",
    "    return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    page = get_web_page(Y_MOVIE_URL)\n",
    "    if page:\n",
    "        movies = get_movies(page)\n",
    "        for movie in movies:\n",
    "            print(movie)\n",
    "        with open('movie.json', 'w', encoding='UTF-8') as file:\n",
    "            json.dump(movies, file, indent=2, sort_keys=True, ensure_ascii=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬取Yahoo本周電影新片資訊(所有頁)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抓取: 第1頁 網路資料中...\n",
      "等待5秒鐘...\n",
      "抓取: 第2頁 網路資料中...\n",
      "等待5秒鐘...\n",
      "['中文片名', '英文片名', '期待度', '海報圖片', '上映日']\n",
      "['音速小子', 'Sonic the Hedgehog', '69%', 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/November2019/4i6xD3LunZdexYMy7tKt-800x1185.jpg', '2020-02-21']\n",
      "['李察朱威爾事件', 'Richard Jewell', '93%', 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/January2020/nLPG6MdEBYVyelqnY7wn-504x720.jpg', '2020-02-21']\n",
      "['絕命大平台', 'The Platform', '76%', 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/January2020/0VRicXOeicftTggp8zG1-3000x4275.jpg', '2020-02-21']\n",
      "['陰櫥', 'The Closet', '86%', 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/February2020/2oQG8URZbVXQQoHaIAmm-992x1418.JPG', '2020-02-21']\n",
      "['咒怨 電影版', 'Ju-On', '78%', 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/January2020/Wc2DbLSmzS7rBcIBnnDT-500x714.jpg', '2020-02-21']\n",
      "['少年阿罕默德', 'Young Ahmed', '58%', 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/January2020/13eahGU5buNr8RKf60QP-506x720.jpg', '2020-02-21']\n",
      "['閃閃小超人電影版', 'SamSam', '64%', 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/January2020/wPnAXlYL2VzzWcOyyTYs-840x1200.jpg', '2020-02-21']\n",
      "['吹哨奇案', 'La Gomera', '58%', 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/February2020/qTIIR21VYMca7JvhjJxL-2874x4096.jpg', '2020-02-21']\n",
      "['悲慘世界', 'Les Misérables', '60%', 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/February2020/vxtsrQvIAR2PNfyADiNj-1280x1829.jpg', '2020-02-21']\n",
      "['電影音效傳奇：好萊塢之聲', 'Making Waves : The Art of Cinematic Sound', '80%', 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/February2020/2vFOZcDEwWz0VVOxvQlI-934x1329.jpg', '2020-02-21']\n",
      "['失路人', 'Someone who was lost', '75%', 'https://movies.yahoo.com.tw/x/r/w420/i/o/production/movies/February2020/8qiE1jsMrQd0VIPbOELp-495x720.jpg', '2020-02-21']\n"
     ]
    }
   ],
   "source": [
    "#Ch9_2(yahoo_movie_crawler.py)-爬取Yahoo本周電影新片資訊\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 目標URL網址\n",
    "URL = \"https://movies.yahoo.com.tw/movie_thisweek.html?page={0}\"\n",
    "\n",
    "def generate_urls(url, start_page, end_page): #使用參數基底URL、開始和結束頁數來建立URL清單\n",
    "    urls = []   #爬蟲主程式建立的目標網址清單\n",
    "    for page in range(start_page, end_page+1):  \n",
    "        urls.append(url.format(page))\n",
    "    return urls\n",
    "\n",
    "def get_resource(url):\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "               \"AppleWebKit/537.36 (KHTML, like Gecko)\"\n",
    "               \"Chrome/63.0.3239.132 Safari/537.36\"}\n",
    "    return requests.get(url, headers=headers) \n",
    "\n",
    "def parse_html(html_str):\n",
    "    return BeautifulSoup(html_str, \"lxml\")\n",
    "\n",
    "\n",
    "def format_date(date_str):  #使用正規表達式取出參數字串中的日期資料\n",
    "    # 取出上映日期\n",
    "    pattern = '\\d+-\\d+-\\d+' #\\d找到數字要找一整組的所以\\d+(+代表1個以上)，匹配字符\"-\"，這樣子就可以從資料中抓到要的東西了\n",
    "    match = re.search(pattern, date_str) #re.search(匹配的正則表達式,要匹配的字符串):掃描整個字符串並返回第一個成功的匹配\n",
    "    if match is None:\n",
    "        return date_str\n",
    "    else:\n",
    "        return match.group(0)\n",
    "\n",
    "#用for迴圈取出每一部新片的資料並建立moive清單，再新增至巢狀清單movies\n",
    "def get_movies(soup):\n",
    "    movies = []\n",
    "    rows = soup.find_all(\"div\", class_=\"release_info_text\")  #找出單獨包含某電影的所有資訊區塊，定位出其中一個，藉著這個find_all找出複數個\n",
    "    for row in rows:  #row為其中一個，rows為複數個，#row無須賦值，在這個位置就代表為rows位置的其中一個\n",
    "        movie_name_div = row.find(\"div\", class_=\"release_movie_name\")  #這裡用row，表示只找複數個中的某個(因在迴圈中所以會照順序找)\n",
    "        cht_name = movie_name_div.a.text.strip()  #strip()去除首尾空格\n",
    "        eng_name = movie_name_div.find(\"div\", class_=\"en\").a.text.strip()\n",
    "        expectation = row.find(\"div\", class_=\"leveltext\").span.text.strip()\n",
    "        photo = row.parent.find_previous_sibling(\"div\", class_=\"release_foto\")  \n",
    "        #因為照片區塊在row的範圍外，要用到走訪，用parent往上層到<release_info>，previous_sibling往同層前一個到<release_foto>，\n",
    "        poster_url = photo.a.img[\"src\"] #於是訂位出照片的網址\n",
    "        release_date = format_date(row.find('div', 'release_movie_time').text) #找出上映日期，但帶入公式轉換成我們要的格式\n",
    "        \n",
    "        movie= [cht_name, eng_name, expectation, poster_url, release_date] #照這個順序放入movie中\n",
    "        movies.append(movie) #再將movie新增至movies = []\n",
    "    return movies  #傳回movies\n",
    "\n",
    "def save_to_csv(items, file):\n",
    "    with open(file, \"w+\", newline=\"\", encoding=\"utf-8\") as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        for item in items:\n",
    "            writer.writerow(item)\n",
    "\n",
    "#使用for迴圈來一一爬取參數的URL清單，每次爬取一頁分頁\n",
    "def web_scraping_bot(urls):\n",
    "    all_movies = [[\"中文片名\",\"英文片名\",\"期待度\",\"海報圖片\",\"上映日\"]]  #巢狀清單\n",
    "    page = 1\n",
    "    \n",
    "    for url in urls:\n",
    "        print(\"抓取: 第\" + str(page) + \"頁 網路資料中...\")\n",
    "        page = page + 1\n",
    "        r = get_resource(url)\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            soup = parse_html(r.text)\n",
    "            movies = get_movies(soup)\n",
    "            all_movies = all_movies + movies\n",
    "            print(\"等待5秒鐘...\")\n",
    "            if soup.find(\"li\", class_=\"nexttxt disabled\"):\n",
    "                break   #已經沒有下一頁\n",
    "            time.sleep(5) \n",
    "        else:\n",
    "            print(\"HTTP請求錯誤...\")\n",
    "\n",
    "    return all_movies\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    urls = generate_urls(URL, 1, 5) #在generate_urls函數產生1~5頁的URL清單(最多5頁，大多只有兩頁)\n",
    "    # print(urls)\n",
    "    movies = web_scraping_bot(urls) #呼叫web_scraping_bot函數爬取各分頁的本周新片資料\n",
    "    for movie in movies:\n",
    "        print(movie)\n",
    "    save_to_csv(movies, \"movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube影片標題爬蟲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}\n",
    "url = 'https://www.youtube.com/channel/UCFdTiwvDjyc62DBWrlYDtlQ/videos?sort=p&view=0&flow=grid'\n",
    "resp = requests.get(url,headers=headers)\n",
    "soup = BeautifulSoup(resp.text, 'lxml')\n",
    "target=soup.find_all('a')\n",
    "#存成txt檔案\n",
    "txt = open('video-title.txt', 'w', encoding = 'UTF-8')\n",
    "for i in target:\n",
    "    f=i.get_text().strip() #取得文字、去除左右的空格\n",
    "    txt.write(f)           #寫入文字\n",
    "    txt.write('\\n')        #換行\n",
    "txt.close()                #關閉檔案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube熱門影片標題爬蟲，並存至txt當中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=\"https://www.youtube.com/feed/trending/\"\n",
    "request=requests.get(url)\n",
    "content=request.content\n",
    "soup=BeautifulSoup(content,\"html.parser\")\n",
    "container = soup.select(\"h3 a\")\n",
    "# 寫入result.txt檔案\n",
    "file = open('result.txt','w')\n",
    "for item in container:\n",
    "    if item:\n",
    "        value = item.get_text()\n",
    "        print(value)\n",
    "        file.write(value+'\\n')\n",
    "file.close()\n",
    "#存成txt檔案\n",
    "txt = open('video-title.txt', 'w', encoding = 'UTF-8')\n",
    "    for i in target:\n",
    "    f=i.get_text().strip() #取得文字、去除左右的空格\n",
    "    txt.write(f)           #寫入文字\n",
    "    txt.write('\\n')        #換行\n",
    "txt.close()                #關閉檔案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yahoo 奇摩字典\n",
    "這個範例有一個要注意的地方, 就是header要記得帶入referer參數, 不然你看到的字典頁面會跟你從yahoo導過去的字典頁面有所差異."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dr.eye 譯典通 Java KK[ˋdʒɑvə] DJ[ˋdʒɑ:və] 美式   n. 爪哇；爪哇產的咖啡  \n",
      "\n",
      "KK[ˋdʒɑvə]  \n",
      "\n",
      "DJ[ˋdʒɑ:və]  \n",
      "\n",
      "n. 爪哇；爪哇產的咖啡  \n",
      "\n",
      "釋義相關詞n.名詞 1. 爪哇 2. 爪哇產的咖啡 3. 【電腦】在網際網路上的應用程式開發語言 Java man ph. 爪哇猿人  Dr.eye 譯典通片語 Hot Java ph. 【電腦】一個由Sun Microsystems開發的可讀Java文件的瀏覽器  Dr.eye 譯典通片語 Java Applet ph. 【電腦】一Java程式可被包含在HTML頁面中  Dr.eye 譯典通片語 Java Applet ph. 【電腦】一Java程式可被包含在HTML頁面中  Dr.eye 譯典通 Hot Java ph. 【電腦】一個由Sun Microsystems開發的可讀Java文件的瀏覽器  Dr.eye 譯典通 Java man ph. 爪哇猿人  Dr.eye 譯典通 上一頁12下一頁 \n",
      "\n",
      "釋義 \n",
      "\n",
      "相關詞 \n",
      "\n",
      "1. 爪哇  \n",
      "\n",
      "2. 爪哇產的咖啡  \n",
      "\n",
      "3. 【電腦】在網際網路上的應用程式開發語言  \n",
      "\n",
      "ph. 爪哇猿人  \n",
      "\n",
      "ph. 【電腦】一個由Sun Microsystems開發的可讀Java文件的瀏覽器  \n",
      "\n",
      "ph. 【電腦】一Java程式可被包含在HTML頁面中  \n",
      "\n",
      "ph. 【電腦】一Java程式可被包含在HTML頁面中  \n",
      "\n",
      "ph. 【電腦】一個由Sun Microsystems開發的可讀Java文件的瀏覽器  \n",
      "\n",
      "ph. 爪哇猿人  \n",
      "\n",
      "上一頁 \n",
      "\n",
      "1 \n",
      "\n",
      "2 \n",
      "\n",
      "下一頁 \n",
      "\n",
      "更多解釋Java IPA[ˈdʒɑːvə] pr n 爪哇島 n. Java語言  牛津中文字典 java IPA[ˈdʒɑːvə] 美式   英式   n. 咖啡  牛津中文字典 Java 爪哇,爪哇產的咖啡,咖啡  PyDict  \n",
      "\n",
      "更多解釋 \n",
      "\n",
      "IPA[ˈdʒɑːvə]  \n",
      "\n",
      "pr n 爪哇島  \n",
      "\n",
      "n. Java語言  \n",
      "\n",
      "IPA[ˈdʒɑːvə]  \n",
      "\n",
      "n. 咖啡  \n",
      "\n",
      "爪哇,爪哇產的咖啡,咖啡  \n",
      "\n",
      "知識+ JAVA作業的問題~急...括弧，修正以上問題後..... 以下是 compile 以及執行的結果：  >javac EX3_1.java >java EX3_1 -485266688 32 86 130  >  另外 main 中列印出的 b 變數值... Java原文書翻譯...省略比較容易懂。    留白   一些有趣的迴圈變化，可在迴圈定義內留白達成。  寫Java時，讓for loop 部分或全部的初始值、條件值、或是循環部分保持空白，是可行... java安裝完一開始就不能執行java指令請問你裝JRE還是JDK?  JRE可以RUN JAVA的程式  但是不能編譯唷(JAVAC)    要編譯要安裝JDK(J2SE... 查看更多 Java 知識+相關結果 >  \n",
      "\n",
      "JAVA作業的問題~急...括弧，修正以上問題後..... 以下是 compile 以及執行的結果：  >javac EX3_1.java >java EX3_1 -485266688 32 86 130  >  另外 main 中列印出的 b 變數值...  \n",
      "\n",
      "Java原文書翻譯...省略比較容易懂。    留白   一些有趣的迴圈變化，可在迴圈定義內留白達成。  寫Java時，讓for loop 部分或全部的初始值、條件值、或是循環部分保持空白，是可行...  \n",
      "\n",
      "java安裝完一開始就不能執行java指令請問你裝JRE還是JDK?  JRE可以RUN JAVA的程式  但是不能編譯唷(JAVAC)    要編譯要安裝JDK(J2SE...  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "\n",
    "\n",
    "YAHOO_DICTIONARY_URL = \"https://tw.dictionary.yahoo.com/dictionary?p=\"\n",
    "YAHOO_REFERER_VALUE = \"https://tw.dictionary.yahoo.com/dictionary\"\n",
    "\n",
    "\n",
    "def get_web_content(url, query):\n",
    "    query = urllib.parse.quote_plus(query)\n",
    "    resp = requests.get(url + query, headers={'Referer': YAHOO_REFERER_VALUE})\n",
    "    if resp.status_code != 200:\n",
    "        print('Invalid url: ', resp.url)\n",
    "        return None\n",
    "    else:\n",
    "        return resp.text\n",
    "\n",
    "\n",
    "def get_dict_info(dom):\n",
    "    soup = BeautifulSoup(dom, 'html5lib')\n",
    "    for explain in soup.find('ol', 'mb-15 reg searchCenterMiddle').find_all('li'):\n",
    "        print(explain.text,'\\n')\n",
    "\n",
    "\n",
    "def main():\n",
    "    page = get_web_content(YAHOO_DICTIONARY_URL, 'Java')\n",
    "    if page:\n",
    "        get_dict_info(page)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 遍歷【Yahoo商城】各商品爬取細節_20200617未完版:get_goods中的\"細項\"欄位還無法拆開抓\n",
    "1. 先取得搜尋頁數的網址List\n",
    "2. 進入每個商品頁面\n",
    "3. 爬取進入頁面之商品細節"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://tw.search.mall.yahoo.com/search/mall/product?cid=979311985&clv=4&p=昆盈&pg=0&qt=product', 'https://tw.search.mall.yahoo.com/search/mall/product?cid=979311985&clv=4&p=昆盈&pg=1&qt=product']\n",
      "Crawing No.1 Item in Total:4Item\n",
      "Crawing No.2 Item in Total:4Item\n",
      "Crawing No.3 Item in Total:4Item\n",
      "Crawing No.4 Item in Total:4Item\n"
     ]
    }
   ],
   "source": [
    "import re, time, requests, csv\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "#解析(蝦皮headers要用Googlebot)\n",
    "def get_soup(url):\n",
    "    #headers = {\"user-agent\": \"Googlebot\"}\n",
    "    res = requests.get(url)\n",
    "    return BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "#搜尋網址&換頁\n",
    "def get_urls(url, query, start_page, end_page): \n",
    "    urls = []\n",
    "    \n",
    "    for page in range(start_page, end_page+1):\n",
    "        urls.append(url.format(query, page))    #query帶入url的{0}、page帶入{1}\n",
    "    print(urls)    \n",
    "    return urls\n",
    "\n",
    "# 依序爬取每頁點入網址\n",
    "def FindLinks(pages):\n",
    "    linklist = []\n",
    "    for page in pages:  \n",
    "        soup = get_soup(page)\n",
    "        links = soup.find_all('a', {'class':'BaseGridItem__content___3LORP'})\n",
    "        for link in links:\n",
    "            k = link.get('href')\n",
    "            linklist.append(k)\n",
    "    return linklist\n",
    "\n",
    "# 爬取點入分頁資料\n",
    "def get_goods(url):\n",
    "    goods = []\n",
    "    rows = get_soup(url)\n",
    "\n",
    "    for row in rows:\n",
    "\n",
    "        try:\n",
    "            name = row.find('div', 'right clearfix').text\n",
    "        except:\n",
    "            name = None\n",
    "\n",
    "        try:\n",
    "            price = row.find('span', attrs={'class':'has_promo_price'}).text\n",
    "        except:\n",
    "            price = None\n",
    "            \n",
    "        try:\n",
    "            Activity_price = row.find('span',attrs={'class':'price'}).text\n",
    "        except:\n",
    "            Activity_price = None\n",
    "            \n",
    "        try:\n",
    "            star = row.find('em', 'store').text\n",
    "        except:\n",
    "            star = None\n",
    "\n",
    "        try:\n",
    "            description = row.find(\"div\", \"top\").p.span.get_text()\n",
    "        except:\n",
    "            description = None\n",
    "            \n",
    "        try:\n",
    "            Detail = row.select_one(\"#ypsiif li span\").find_parent().find_parent().get_text().splitlines() #splitlines()對換行符號進行分割\n",
    "        except:\n",
    "            Detail = None\n",
    "            \n",
    "        \"\"\"只能照順序抓，但無法對準欄位名稱，因為可能會有漏\n",
    "        \n",
    "        try:\n",
    "            Product_Number = Detail[Detail.find(\"商品編號：\")+5 : Detail.find(\"店家貨號：\")]\n",
    "        except:\n",
    "            Product_Number = None\n",
    "\n",
    "        try:\n",
    "            Store_Number = Detail[Detail.find(\"店家貨號：\")+5 : Detail.find(\"購買人次：\")]\n",
    "        except:\n",
    "            Store_Number = None\n",
    "\n",
    "        try:\n",
    "            Purchases = Detail[Detail.find(\"購買人次：\")+5 : Detail.find(\" 銷售件數：\")]\n",
    "        except:\n",
    "            Purchases = None\n",
    "\n",
    "        try:\n",
    "            Sales = Detail[Detail.find(\" 銷售件數：\")+5 : -1]\n",
    "        except:\n",
    "            Sales = None\"\"\"\n",
    "            \n",
    "        \n",
    "            \n",
    "        try:\n",
    "            URL = url\n",
    "        except:\n",
    "            URL = None\n",
    "        \n",
    "        good= [name, price, Activity_price, star, description, Detail, URL]\n",
    "        #good= [name, price, Activity_price, star, description, Product_Number, Store_Number, Purchases, Sales, URL]\n",
    "        goods.append(good)\n",
    "        \n",
    "    return goods[1]  #因為不知為何第[0]列都會出現一排None，只好取第[1]列\n",
    "\n",
    "# 將每一個點入頁面的List依序爬取\n",
    "def scraping(urls):\n",
    "    all_goods = [[\"商品名稱\", \"網路價\", \"活動價\", \"消費者滿意度\", \"商品敘述\", \"細項\", \"網址\"]]\n",
    "    #all_goods = [[\"商品名稱\", \"網路價\", \"活動價\", \"消費者滿意度\", \"商品敘述\", \"商品編號\", \"店家貨號\", \"購買人次\",\"銷售件數\", \"網址\"]]\n",
    "\n",
    "    for idx,i in enumerate(FindLinks(urls)):  #記錄目前進行的迴圈次數，配上總迴圈次數，可做為進度條使用。\n",
    "        print(\"Crawing No.\" + str(idx+1) + \" Item in Total:\" + str(len(FindLinks(urls))) + \"Item\")\n",
    "        \n",
    "        goods = get_goods(i)\n",
    "        time.sleep(0.2)\n",
    "        all_goods.append(goods)\n",
    "    return all_goods\n",
    "#存成CSV\n",
    "def save_to_csv(items, file):\n",
    "    with open(file, \"w+\", newline=\"\", encoding=\"utf_8_sig\") as fp:  #utf_8_sig:能讓輸出的csv正確顯示中文(utf_8會有亂碼)\n",
    "        writer = csv.writer(fp)\n",
    "        for item in items:\n",
    "            writer.writerow(item)\n",
    "    \n",
    "# 開始爬蟲\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"直接在YahooMall搜尋\"\"\"\n",
    "    url = \"https://tw.search.mall.yahoo.com/search/mall/product?cid=979311985&clv=4&p={0}&pg={1}&qt=product\"\n",
    "    \n",
    "    urls = get_urls(url, \"昆盈\", 0, 1)\n",
    "    \n",
    "    m = scraping(urls)\n",
    "    save_to_csv(m, \"m.csv\")\n",
    "    \n",
    "    \n",
    "    \"\"\"測試拆解幾行文字\n",
    "    ex :商品編號：p090415882600\n",
    "        店家貨號：72USGE0009\n",
    "        購買人次：0\n",
    "        銷售件數：0\n",
    "    url = \"https://tw.mall.yahoo.com/item/Genius-%E6%98%86%E7%9B%88-MAURUS-%E6%B2%99%E6%BC%A0%E9%BB%83%E9%87%91%E8%A0%8D-FPS-%E5%B0%88%E6%A5%AD-%E9%9B%BB%E7%AB%B6%E6%BB%91%E9%BC%A0-p090415882600\"\n",
    "    a = get_soup(url).select_one(\"#ypsiif li span\").find_parent().find_parent().get_text()\n",
    "    b = a.splitlines()\n",
    "    #.find(\"li\", text=\"店家貨號：\")\n",
    "    #b = a.replace(\"\\n\", \",\")\n",
    "    b.find()\n",
    "    print(b) \n",
    "    #c = a.find(\"店家貨號：\")\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
